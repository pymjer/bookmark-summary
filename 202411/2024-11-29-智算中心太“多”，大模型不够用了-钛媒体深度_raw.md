Title: 智算中心太“多”，大模型不够用了 | 钛媒体深度

URL Source: https://mp.weixin.qq.com/s/Mpy-AbQmu5y2PLXfyNxkFw

Markdown Content:
Original 张帅 钛媒体 _2024年11月20日 04:17_

![Image 27](https://mmbiz.qpic.cn/mmbiz_gif/OaFsUa11r0CALGfmcHTGJLo2T5jniaTo8Kg7s8ZwlUX6ostHVrZnl2d96wA7AkaIoTdFlfJqurGVV2ve19A2eog/640?wx_fmt=gif&from=appmsg)

![Image 28](https://mmbiz.qpic.cn/mmbiz_png/OaFsUa11r0AXiaCyRNYjSa7BtujE6Gr7TQpEkMja7jrlJdzwGxRicLlzlGA0NCOibVUTsdIF3uhQ9gvKugaGsaD2Q/640?wx_fmt=png&from=appmsg)

##### **▎****缺算力是真的，空置也是真的。**

作者｜张帅

编辑｜盖虹达

本文首发于钛媒体APP

英伟达芯片“倒爷”们，开始不发朋友圈了。

2023年大模型火热的时候，“倒爷”们朋友圈的画风是“欲购从速、30%定金，有实力的老板来！”到了2024年就变成了“现货现款、物美价优。”甚至有一批人已经黯然退场。

以H100整机价格为例，官方售价为30万美元左右，水货一度高达300多万人民币，超过50%的利润空间，让不少人趋之若鹜，但是现在价格已经回落到230万人民币左右，再倒卖也就没什么利润空间。

其中既有英伟达芯片更新换代的原因，基于Blackwell架构的GB200等新品单位算力成本更低；也有算力行业从过热到回归理性的必然，有了GPU并不意味能转换成大模型算力，大家对这一现实的理解，是用真金白银砸出来的。

大模型之大，动辄需要64/128/256台服务器（一台服务器8张GPU卡）组成的算力集群来训练。对于志在基础大模型的厂商来说，万卡集群成了入门门槛，不仅海外OpenAI、马斯克的xAI等都在规划十万卡集群，国内也同样走在竞逐十万卡集群的路上。

来自需求端的压力，也正在重新校正AI算力产业，首当其冲的便是智算中心。作为计算、存储、网络的集合体，智算中心直接反映大模型算力的行业现状，而来自一线的声音趋于一致：智算中心太“多”，大模型不够用了。

**缺算力是真的，空置也是真的**
-----------------

![Image 29](https://mmbiz.qpic.cn/mmbiz_png/OaFsUa11r0Aibict80r8B3FAPhjUxwC86rR7HhKicIc2liaXJg9KKUtS6lRbyOicFQ5MWUfh1cCnMvlJHiaoVyTyRkNQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1&tp=wxpic)  

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

智算中心并不是绝对意义上的“多”，无论从各种视角看，真正适配大模型训练的算力在未来一段时间仍有很大的缺口，大规模智算中心的建设不会停止。

以OpenAI为代表，ChatGPT发布两年来，大模型产业发展的脚步似乎变慢了，不排除这是大模型新一轮爆发前的蛰伏，在“Scaling Law”（规模法则）信仰之下，xAI、Meta、OpenAI等巨头都在积极布局十万卡乃至更大规模的智算集群。

例如7月份，马斯克宣布位于美国田纳西州孟菲斯市的超级集群开始投入训练，该集群配备了10万个英伟达 H100 GPU，被称为 “世界上最强大的 AI 训练集群”。两个月后，马斯克宣布该集群名为 “Colossus（巨人）”，将在未来几个月内再增加 10 万颗 GPU，其中 5 万颗将是更为先进的英伟达 H200，Grok 3训练预计在三到四个月内于该集群完成，目标是12月发布。

再看OpenAI，甚至因为算力交付和“铁杆盟友”微软产生了分歧。此前微软与 OpenAI 合作共建一个代号为 “星际之门” 的巨型数据中心项目，项目预计成本超过 1150 亿美元，旨在建设一个配备数百万块 GPU 的超级计算机。据报道，微软计划到2025年底向 OpenAI 提供约 30 万个英伟达最新的 GB200。

但是奥尔特曼似乎对微软的速度还不满意，在完成66亿美元的最新一笔融资后，OpenAI又与甲骨文达成合作，将在德克萨斯州的一个新数据中心租用服务器，该数据中心未来可容纳数十万个英伟达GPU。

![Image 30](https://mmbiz.qpic.cn/mmbiz_jpg/OaFsUa11r0AXiaCyRNYjSa7BtujE6Gr7TDY4Rg1PSXon9znemnMrf7g5GSsrLqZ80d7UE6OlqSdeLNLIMibIV4zw/640?wx_fmt=jpeg&from=appmsg)

图片系AI生成

超大规模数据中心解决方案运营商秦淮数据对钛媒体APP表示，公司坚定看多智算，预计2027年开始智算需求进一步爆发，到2030年100%的推理需求都需要由超大规模数据中心来完成。

赛迪顾问人工智能与大数据研究中心高级分析师白润轩此前表示， 截至2024年上半年，国内已经建设和正在建设的智算中心超过250个，2024年上半年智算中心招投标相关事件791起，同比增长高达407.1%。

“这表明智算中心的建设在全国范围内得到了广泛的关注和支持。从2023年开始，各地政府加大了对智算中心的投资力度，推动了基础设施的发展。”白润轩说。

百度智能云AI计算部负责人王雁鹏则表示，从需求侧来看，十万卡是今年大模型竞争的规模门槛，从技术角度来看，大模型算力基本估算为模型的大小乘以所需要的数据量，“GPT4是万亿参数，大概用了2-3万张H卡集群训出来GPT4，按照Scaling Law推算，GPT5的集群卡数大概在十万量级，可能是5-10万之间，参数级别会提升大概3-5倍。”

然而，与万卡算力集群火热相对应的，是大模型市场的“冷清”。

据经济观察报统计，截至2024年10月9日，网信办共通过188项生成式人工智能备案，也就是有188个大模型可以上线提供生成式人工智能服务。但超过三成的大模型在通过备案后未进一步公开其进展情况；仅有约一成的大模型仍在加速训练模型；接近一半的大模型则转向了AI应用的开发。

这些迹象可以理解为：大模型预训练需求越来越集中了。

与此同时，国内市场相较于海外市场更复杂。相似之处是算力需求持续增长，不同之处是算力封锁、生态不全，加之前期部分炒货囤卡的行为，这就导致了一种诡异的状态——算力既紧缺又空置。因为，“把GPU卡塞进机房”和“构建用于大模型训练所需的算力集群”，是两个完全不同的概念。

但是，对于智算中心的空置率或者浪费程度，并没有一个统一的答案。从钛媒体APP获得的一份资料可以有个大概感知：上半年国内已上线智算中心17亿卡时，使用5.6亿卡时，利用率32%；另有数据显示，目前算力基础设施行业的平均上架率不足 60%。

**算力空置引起各方关注**
--------------

![Image 31](https://mmbiz.qpic.cn/mmbiz_png/OaFsUa11r0Aibict80r8B3FAPhjUxwC86rR7HhKicIc2liaXJg9KKUtS6lRbyOicFQ5MWUfh1cCnMvlJHiaoVyTyRkNQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1&tp=wxpic)  

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

“各地前期已经建设了一批智算中心，不管是国产卡还是英伟达的卡，这些集群都不同程度上存在闲置问题，政府已经注意到了这些问题，智算中心的运营主体也也不少出现亏损，在算力挑战短时间内很难解决的情况下，投资节奏上还是要有所把控。”一位接近政府的行业侧人士对钛媒体App提到。

国家层面先后推出了十余项政策推进智算中心建设，例如“东数西算”“数字中国建设整体布局规划”等，但上述人士告诉钛媒体App，最近发改委已经基本明确，如果还要进一步新建智算中心，而且是采购国外卡，能耗指标均不予批复。如果采购国产卡，考虑支持国产创新，并且在东数西算的八大节点上，还可以安排能耗指标。

据了解，目前智算中心主要投资模式，一是政府投资建设，建设资金来自地方政府财政资金、专项债券发行等，建成后所有权归政府所有；二是企业独立投资建设，由企业联盟、少数企业联合、单独企业等形式进行投资；三是高校或科研机构独立投资建设，向师生、研究人员提供免费算力支撑，服务高校教育场景，这种情况下建设成本较低。

这其中，有不少智算中心向银行贷款采购GPU卡，承诺兜底方都是几家搞基础大模型的公司，比如阿里巴巴、腾讯、百度等。银行也很疑惑，大模型公司本身就有云基础设施和大量GPU卡，绝大多数中间商的议价权和渠道能力还不如这些大厂，怎么让大厂们加钱采购？

![Image 32](https://mmbiz.qpic.cn/mmbiz_jpg/OaFsUa11r0AXiaCyRNYjSa7BtujE6Gr7T2P0qrRFV1d4QQNSF8iaX4eh040HGMPl6OZbIQUYCSvicE4Wg5mzHOCuw/640?wx_fmt=jpeg&from=appmsg)

钛媒体APP获悉，有地方政府开始斡旋，希望让云厂商租用闲置的智算中心算力。“我们都不知道国内还有这么多卡，某种意义上，算力稀缺的背后存在一些资源错配。”上述人士表示。

该人士还提到，政府意识到可能会有算力浪费的情况出现，但是，部分地方手握能耗指标，和供应商拉扯的时间较多，智算中心建得慢，而部分地方建设得快反而亏损，由此带来的负面甚至引起了高层注意。

据悉，工信部日前面向六个城市定向下发了关于智算云服务试点的批文，希望用公共云的方式，解决前期各地方的智算中心建设问题，特别是国有资金建设的一些小散算力中心浪费问题。

近几个月来，政府侧已经出台多项政策，正强调有序引导，出清落后产能。

例如《数据中心绿色低碳发展专项行动计划》发布，对数据中心行业的区域布局、能效水效、绿电使用进行了严格、全面的规定，并提出“全面清理地方高耗能电价优惠政策”，舆论普遍认为该政策将加速落后产能淘汰，从而改善行业供给结构，促进行业良性发展。

8 月 1 日，《公平竞争审查条例》正式实施，要求各地方政府“没有法律法规依据或国务院批准，不得给予特定经营者税收优惠”，这意味着盛行已久的地方“以税引商”模式被按下了暂停键，企业将更关注经营本身，有利于行业从“卷价格”走向“卷创新”。

云计算行业也看到了智算中心建设的问题。阿里云智能科技研究中心主任安琳提到，目前有三种“万卡集群：

假万卡集群——公司确实有一万张AI加速卡（GPU卡），但分布在全国几个不同的数据中心，每个数据中心有几百张或几千卡，加起来超过万卡。这种集群是“假万卡集群”。

伪万卡集群——拥有一万张AI加速卡且部署在同一个数据中心，但训练特定模型的时候，只有一部分卡实际参与训练。例如：1000卡训练A模型，2000张卡训练B模型，3000张卡训练C模型，4000张卡训练D模型。这种万卡集群是“伪万卡集群”。

真万卡集群——单一集群拥有一万张AI加速卡（如GPU卡），部署在同一个数据中心，并且能通过大规模资源调度技术，让万卡作为“一台”计算机，单一模型能在这一万张卡上同时进行训练。正如100个昆明湖连起来，也训不出一支航母舰队，大模型也是如此，只有真正的万卡智算集群，才能训练出国际先进的大模型。

有数据中心行业人士也表示，数据中心行业对内卷严重的感知非常明显，比如很多数据中心企业无条件为客户预留资源；签订短期租约，客户拥有随时调价调量的权益；过度扩大责任范围；招投标突破合理价格底线等等，这都是一些内卷带来的乱象。

**为什么大模型算力会闲置？**
----------------

![Image 33](https://mmbiz.qpic.cn/mmbiz_png/OaFsUa11r0Aibict80r8B3FAPhjUxwC86rR7HhKicIc2liaXJg9KKUtS6lRbyOicFQ5MWUfh1cCnMvlJHiaoVyTyRkNQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1&tp=wxpic)  

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

在回答这一问题之前，有必要捋清下大模型所需的算力类型。

目前大模型所需的算力主要有三种，其一是超大规模的大模型训练，需要的算力集群越来越大，智算中心供不应求；其二是常规的大模型训练/微调，一般的裸金属或者算力集群都能满足；其三是推理需求，用云主机等都能满足，未来需求有望稳定增长。

可以看出，除了第一种基础大模型的训练需求之外，其余的大模型算力需求并不十分紧缺，不用最新的英伟达GPU卡，国产AI芯片也能顶上，企业可以在价格、成本、易用性等因素之间寻找平衡点。

ZStack CTO王为提到了一个很有意思的现象，也是国内企业不得已为之的权宜之计——他表示，企业对于AI的投入还是相对比较谨慎的，在很多场景下用消费级显卡，很大程度上解决了大模型非预训练的需求。

对于云厂商而言，按照正常的生意逻辑，一边买卡一边以云服务的形式卖出去，不会大肆囤卡，其他的囤卡行为显然没有充分认识到，卖卡这门生意有多难。

租卡也是一种节省成本的方法，GPU正在更新换代，但不是简单的付租金就行，云厂商还要带着工程团队去做大量改造，估算地价、电价等，额外配置交换机、网卡、光缆等，任何资本支出都要盘算是否值得投入。

安琳进一步补充道，智算中心的三大主要门槛包括集群网络、任务调度、智能运维。王雁鹏也表示，国内构建10万卡集群面临着三大难题，跨地域部署、多芯混训以及集群稳定性，这些难题包括技术和工程上的多重挑战。

首先是网络，大模型催生了一种全新的网络需求，此前从未有过，也就没有相应的成熟方案，市面上所有方案都是边研发边使用，可以说，网络技术直接决定集群规模能建多大。

“几百G的带宽，在每一个毫秒范围内正向模型训练带宽全占满，下一个毫秒又反向全占满回来，在人类历史上的通信，没碰到过这种需求。

这涉及到诸多软件硬件，交换机、网卡芯片硬件和软件设计，路径选择的算法、通信协议的加速。要干这件事，网卡、交换机甚至中间用的光缆都得专门定制。”安琳说道，阿里云AI高性能网络架构HPN 7.0成果论文被SIGCOMM2024收录，成为SIGCOMM历史上首篇关于AI智算集群网络架构的论文。

其次是调度，算力集群规模小，网络当然简单，但是效率和规模就没有竞争力，如何让计算任务灵活的在硬件资源调度，资产利用率就能越高，算力价格就可以做到更低。

传统思路是按照硬件资源做调度，先监测算力卡是否空闲，如果闲着了就给他扔一个任务过去，这是最简单且效率极低的调度，云计算行业早已经进化到按任务来调度，可以监测到每一张卡上每一个任务的进程，然后根据任务进程分配新的任务。

安琳强调，“不是简单地给算力卡安排任务，而是把更细颗粒度的一个个不同的计算任务在这些卡间做调度，需要很多的工程技术能力积累，这也是为什么现在全世界做得好的AI公司，基本上都属于云计算公司。”

最后是运维，在以前的计算中，算力卡坏了可以很快将其隔离，然后继续用其他卡运行，现在大模型有很多瞬时故障，在毫秒级时间有抖动，一次通信过程中的抖动和丢包，就会导致GPU利用率下降50%。据安琳介绍，阿里云已经升级到毫秒级检测，及时从集群里隔离故障算力。

![Image 34](https://mmbiz.qpic.cn/mmbiz_jpg/OaFsUa11r0AXiaCyRNYjSa7BtujE6Gr7TQEcgZhSbfh6a9yjpHSC7PCAPTRx6no2FD9lO7NZ1DrU9CtRianR99dw/640?wx_fmt=jpeg&from=appmsg)

此外，国内企业构建算力集群还面临着一个现实的困难：芯片。

国内企业面临算力供应不稳定的挑战，较难构建单一大规模训练集群。

现实情况是，企业内部会出现同一厂商不同代际芯片，或者不同厂商芯片共存的情况。这些芯片如何进行混部训练，同时保证混部训练的效率也是难题。

此外，随着芯片集成度的不断提高，芯片的故障率也会相应上升，英伟达H系列芯片的故障率比A系列高3-4倍。并且算力集群规模越大，其故障率就越高。按照H系列芯片的故障率水平，十万卡集群每20分钟就会出现故障。较高的故障率对稳定性训练保障提出了更高的要求。

王雁鹏介绍，包括百度在内的国内厂商正在破解这些难题。在跨地域方面，针对由于传输距离变长所产生的高延迟，百舸4.0已经构建了十万卡级别的超大规模HPN高性能网络，通过提供更高效的拓扑结构、更优的多路径负载均衡策略及通信策略，能够实现几十公里的跨地域通信。同时，在通信效率上，通过优化的拥塞控制算法、集合通信算法策略，将带宽有效率提升至95%，实现了完全无阻塞。最后，通过10ms级别超高精度网络监控，保障了网络稳定性。

**智算中心，从内卷走向有序**
----------------

![Image 35](https://mmbiz.qpic.cn/mmbiz_png/OaFsUa11r0Aibict80r8B3FAPhjUxwC86rR7HhKicIc2liaXJg9KKUtS6lRbyOicFQ5MWUfh1cCnMvlJHiaoVyTyRkNQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1&tp=wxpic)  

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

对于智算中心的建设是否过于超前，不同人有不同看法。一方认为，国内智算中心还无法摆脱海外生态体系，需要三到五年的过渡期，在此过程中，大规模加速建设智算中心必然会带来大量浪费。

另一方认为，海外封锁只会愈发严峻，国产算力生态必须加速成熟，相比于国家战略的竞争，超前建设带来的一些小问题是可以接受的。有消息显示，受到美方要求，台积电被迫采取临时策略，将暂停向大陆AI算力芯片客户供应7nm工艺及以下更先进制程的代工服务。

目前来看，囤积英伟达卡的确带来一部分算力浪费，如上所述，很多购卡方不具备智算中心所需的网络、调度和运维能力。一位智算中心技术专家直言，“之前太多的投机倒把，很多都不是干这个行业的，觉得囤货就能挣钱，把它塞到一个机房里面去，稳定性，各种容错，乱七八糟的问题都解决不了，造成了很多浪费。

国产算力也同样存在问题，该专家谈及国产AI算力的浪费时感慨，“华为的运营能力太强，在大家还没有准备好用国产卡和用华为的时候，花了大力气搞算力场、智算中心，运营商建了大几万卡的集群，它的芯片距离客户开箱即用，到真正能用好还有一些距离，接下来会有更多的国产芯片进来，这个问题会进一步放大。”

“但是对于整体国产卡这件事情我比较乐观，基于大模型时代算力格局变化。原来的模型非常分散，CUDA生态非常厉害是因为要兼容那么多模型，现在大模型比较收敛的情况下，大家的主流框架是一样的；同时英伟达又这么贵，再考虑到算力可获得性问题，大家就会更愿意尝试用国产卡。”他补充表示。

近日，《科技日报》也头版刊登了全国政协委员张云泉署名文章《智算中心建设不可盲目跟风》，文章强调，智算中心的建设需要巨额资金投入，而投资回报却不确定。

文章表示，由于智算技术更新迭代很快，智算中心的生命周期一般只有5至10年，如果没有强大的技术储备和升级能力，就可能陷入不断投入却无法跟上技术发展步伐的困境。另外，智算中心的运营管理离不开专业的技术人才和高效的管理团队，否则就可能无法发挥其应有作用，甚至出现设备闲置、资源浪费等问题。由此看来，智算中心该不该建、能不能建、什么时候建、建在哪里，需要科学、稳慎决策，绝不能头脑发热、一哄而上“赶时髦”。总的原则应当是，在市场需求明确且可持续的情况下，因地制宜、按需建设、适当超前。

一些地方也加强了对智算中心运营的要求，比如山东德州价值约2亿元的“全国一体化工业大数据山东云中心省会经济圈区域分中心数据机房‘德智未来’智算中心项目”，就在招标文件中明确写明了“采用设计施工采购运营一体化的模式建设”，要求运营期限不低于5年，并规定了项目验收投运后每年算力的最低收益。

王为也表示，从政策角度上看，政府对智算中心的要求比以前多，以前是先把智算中心建起来就行，现在建设初期就会找好的运营方，或者建设与运营一体，保证算力的使用率。

“去年算力消耗以训练为主，目前看消解不了算力中心的算力，很多大模型厂商手里囤的算力也不少，一些大模型厂商也减少了预训练，不太需要对外租很大的算力了。现在很多智算中心也开始找一些推理的场景，研究落地应用，使用端会更分散，整个市场应该会更健康。”他说。

**（本文首发于钛媒体APP）**

* * *

_**热点视频推荐**_

___[波士顿动力创始人雷伯特确认出席钛媒体2024 T-EDGE全球创新大会](http://mp.weixin.qq.com/s?__biz=MjM5ODIzNTc2MA==&mid=2661041965&idx=1&sn=0e56ebb21396cadeee3aca711d2d52e7&chksm=bda53c328ad2b5243cff1c8069f2fb04878726f271ff26833aec1ec1187d972f95e8ff5fa7af&scene=21#wechat_redirect)（12月6—7日），并将在中国首次阐释“动力智能机器人的未来”。___

_******__**点赞关注****钛媒体AGI****视频号，观看更多精彩视频**__******_

\*温馨提示：喜欢钛媒体公众号的小伙伴注意啦！根据公众号推送新规，请将钛媒体设为**“星标”**，这样才能第一时间收到推送消息，已设置的小伙伴还需要重新设置**“星标”**哦

****\-----------华丽的分割线------------****

****下载钛媒体App，打开科技，打开财富。****

![Image 36](https://mmbiz.qpic.cn/mmbiz_jpg/OaFsUa11r0C5LBgMclbX8J61vQFticpfC6aYkB2p9GNicOSoW0dKP5S0cTjvgbcyBibwSZlhsdMHAFRZvQIBNCaHw/640?wx_fmt=jpeg&from=appmsg)

![Image 37](https://mmbiz.qpic.cn/mmbiz_png/OaFsUa11r0CGmL1XEviaVKCfnFicdkIeYvmJckbdGCpMiaZZsEC3jHwsbB1OycY3o19GIpSnia1lh0iahBAcDoj8A4g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

万水千山总是情，点个在看行不行
