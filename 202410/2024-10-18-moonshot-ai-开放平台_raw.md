Title: Moonshot AI - 开放平台

URL Source: https://platform.moonshot.cn/docs/intro

Markdown Content:
主要概念
----

文本生成模型[](https://platform.moonshot.cn/docs/intro#%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B)
--------------------------------------------------------------------------------------------------------

Moonshot的文本生成模型（指moonshot-v1）是训练用于理解自然语言和书面语言的，它可以根据输入生成文本输出。对模型的输入也被称为“prompt”。通常我们建议您提供明确的指令以及给出一些范例，来让模型能够完成既定的任务，设计 prompt 本质上就是学会如何“训练”模型。moonshot-v1模型可以用于各种任务，包括内容或代码生成、摘要、对话、创意写作等。

语言模型推理服务[](https://platform.moonshot.cn/docs/intro#%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E6%9C%8D%E5%8A%A1)
----------------------------------------------------------------------------------------------------------------------------

语言模型推理服务是一个基于我们 (Moonshot AI) 开发和训练的预训练模型的 API 服务。在设计上，我们对外主要提供了一个 Chat Completions 接口，它可以用于生成文本，但是它本身是不支持访问网络、数据库等外部资源，也不支持执行任何代码。

Token[](https://platform.moonshot.cn/docs/intro#token)
------------------------------------------------------

文本生成模型以 Token 为基本单位来处理文本。Token 代表常见的字符序列。例如，单个汉字"夔"可能会被分解为若干 Token 的组合，而像"中国"这样短且常见的短语则可能会使用单个 Token。大致来说，对于一段通常的中文文本，1 个 Token 大约相当于 1.5-2 个汉字。

需要注意的是，对于我们的文本模型，Input 和 Output 的总和长度不能超过模型的最大上下文长度。

速率限制[](https://platform.moonshot.cn/docs/intro#%E9%80%9F%E7%8E%87%E9%99%90%E5%88%B6)
------------------------------------------------------------------------------------

这些速率限制是如何工作的？

速率限制通过4种方式衡量：并发、RPM（每分钟请求数）、TPM（每分钟 Token 数）、TPD（每天 Token 数）。速率限制可能会在任何一种选项中达到，取决于哪个先发生。例如，你可能向 ChatCompletions 发送了 20 个请求，每个请求只有 100 个 Token ，那么你就达到了限制（如果你的 RPM 限制是 20），即使你在这些 20 个请求中没有发满 200k 个 Token （假设你的TPM限制是 200k）。

对网关，出于方便考虑，我们会基于请求中的 max\_tokens 参数来计算速率限制。这意味着，如果你的请求中包含了 max\_tokens 参数，我们会使用这个参数来计算速率限制。如果你的请求中没有包含 max\_tokens 参数，我们会使用默认的 max\_tokens 参数来计算速率限制。当你发出请求后，我们会基于你请求的 token 数量加上你 max\_tokens 参数的数量来判断你是否达到了速率限制。而不考虑实际生成的 token 数量。

而在计费环节中，我们会基于你请求的 token 数量加上实际生成的 token 数量来计算费用。

### 其他值得注意的重要事项：[](https://platform.moonshot.cn/docs/intro#%E5%85%B6%E4%BB%96%E5%80%BC%E5%BE%97%E6%B3%A8%E6%84%8F%E7%9A%84%E9%87%8D%E8%A6%81%E4%BA%8B%E9%A1%B9)

*   速率限制是在用户级别而非密钥级别上实施的。
*   目前我们在所有模型中共享速率限制。

模型列表
----

你可以使用我们的 [List Models API](https://platform.moonshot.cn/docs/api-reference#list-models) 来获取当前可用的模型列表。

当前的，我们支持的模型有：

*   `moonshot-v1-8k`: 它是一个长度为 8k 的模型，适用于生成短文本。
*   `moonshot-v1-32k`: 它是一个长度为 32k 的模型，适用于生成长文本。
*   `moonshot-v1-128k`: 它是一个长度为 128k 的模型，适用于生成超长文本。

以上模型的区别在于它们的最大上下文长度，这个长度包括了输入消息和生成的输出，在效果上并没有什么区别。这个主要是为了方便用户选择合适的模型。

使用指南
----

获取 API 密钥[](https://platform.moonshot.cn/docs/intro#%E8%8E%B7%E5%8F%96-api-%E5%AF%86%E9%92%A5)
----------------------------------------------------------------------------------------------

你需要一个 API 密钥来使用我们的服务。你可以在我们的[控制台](https://platform.moonshot.cn/console)中创建一个 API 密钥。

发送请求[](https://platform.moonshot.cn/docs/intro#%E5%8F%91%E9%80%81%E8%AF%B7%E6%B1%82)
------------------------------------------------------------------------------------

你可以使用我们的 Chat Completions API 来发送请求。你需要提供一个 API 密钥和一个模型名称。你可以选择是否使用默认的 max\_tokens 参数，或者自定义 max\_tokens 参数。可以参考 [API 文档](https://platform.moonshot.cn/docs/api-reference#python-%E8%B0%83%E7%94%A8%E6%96%B9%E6%B3%95)中的调用方法。

处理响应[](https://platform.moonshot.cn/docs/intro#%E5%A4%84%E7%90%86%E5%93%8D%E5%BA%94)
------------------------------------------------------------------------------------

通常的，我们会设置一个 5 分钟的超时时间。如果单个请求超过了这个时间，我们会返回一个 504 错误。如果你的请求超过了速率限制，我们会返回一个 429 错误。如果你的请求成功了，我们会返回一个 JSON 格式的响应。

如果是为了快速处理一些任务，你可以使用我们的 Chat Completions API 的非 streaming 模式。这种模式下，我们会在一次请求中返回所有的生成文本。如果你需要更多的控制，你可以使用 streaming 模式。在这种模式下，我们会返回一个 [SSE (opens in a new tab)](https://kimi.moonshot.cn/share/cr7boh3dqn37a5q9tds0) 流，你可以在这个流中获取生成的文本，这样用户体验可能会更好，并且你也可以在任何时候中断请求，而不会浪费资源。

Last updated on September 2, 2024

[Chat](https://platform.moonshot.cn/docs/api/chat "Chat")
