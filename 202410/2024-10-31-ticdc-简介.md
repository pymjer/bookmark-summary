# TiCDC 简介
- URL: https://docs.pingcap.com/zh/tidb/stable/ticdc-overview
- Added At: 2024-10-31 02:12:14
- [Link To Text](2024-10-31-ticdc-简介_raw.md)

## TL;DR
TiCDC 是适用于多 TiDB 集群数据高可用、容灾和实时数据同步到异构系统的解决方案。它具备核心能力如 TiDB 间数据容灾复制、双向复制、低延迟增量数据同步等，并支持至少一次输出和数据复制的最终一致性。TiCDC 架构包括 TiKV Server、TiCDC 和 PD。最佳实践包括合理部署位置和有效索引配置。TiCDC 实现原理涉及实时监听 TiKV Region Raft Log 信息并生成 SQL 语句的数据变更信息。不支持的场景包括 RawKV 的 TiKV 集群、SEQUENCE DDL 操作和函数以及 BR 数据恢复和 TiDB Lightning 物理导入。

## Summary
# TiCDC 简介

## TiCDC 适用场景
- **多 TiDB 集群数据高可用和容灾方案**：保证灾难发生时主备集群数据的最终一致性。
- **实时变更数据同步到异构系统**：为监控、缓存、全文索引、数据分析等场景提供数据源。

## TiCDC 主要特性

### 核心能力
- **TiDB 间数据容灾复制**：实现秒级别 RPO 和分钟级别 RTO。
- **双向复制能力**：支持构建多写多活的 TiDB 集群。
- **低延迟增量数据同步**：支持 TiDB 到 MySQL 或兼容 MySQL 协议数据库。
- **Kafka 增量数据同步**：支持多种数据格式。
- **存储服务增量数据同步**：支持 Amazon S3、GCS、Azure Blob Storage 和 NFS。
- **表级别数据同步**：支持同步过程中过滤数据库、表、DML、DDL。
- **高可用架构**：无单点故障，支持动态添加、删除 TiCDC 节点。
- **Open API 集群管理**：查询任务状态、动态修改任务配置等。

### 数据同步顺序性
- **至少一次输出**：对所有 DDL/DML 都能对外输出至少一次。
- **重复 DDL/DML 处理**：MySQL sink 可以重复执行 DDL，Kafka sink 提供不同的数据分发策略。

### 数据同步一致性
- **MySQL sink 保证**：开启 redo log 后保证数据复制的最终一致性，保证单行更新与上游更新顺序一致。

## TiCDC 架构
- **TiKV Server**：TiDB 集群中的 TiKV 节点，发送变更日志给 TiCDC 节点。
- **TiCDC**：运行 TiCDC 进程的节点，从 TiKV 节点拉取数据改变，并通过 Sink 模块同步到下游系统。
- **PD**：TiDB 集群中的调度模块，负责集群数据的事实调度，内部通过 etcd 集群实现高可用。

## 最佳实践
- **部署位置**：根据版本不同，推荐部署在上游或下游集群所在的区域。
- **有效索引**：TiCDC 同步的表需要至少存在一个有效索引。
- **容灾场景下的 redo log 配置**：为实现最终一致性，需要配置 redo log。

## TiCDC 处理数据变更的实现原理
- **DML 数据变更处理**：实时监听上游 TiKV 各个 Region Raft Log 的信息，并根据事务前后数据的差异生成对应多条 SQL 语句的数据变更信息。
- **数据变更信息**：包含数据变更类型及变更前后的数值，可能产生 `DELETE`、`INSERT`、`UPDATE` 事件。
- **下游适配**：根据收到的数据变更信息，适配各个类型的下游生成合适格式的数据传输。

## 暂不支持的场景
- **RawKV 的 TiKV 集群**：暂不支持单独使用。
- **SEQUENCE DDL 操作和函数**：暂不支持在 TiDB 中创建 SEQUENCE 的 DDL 操作和 SEQUENCE 函数。
- **BR 数据恢复和 TiDB Lightning 物理导入**：暂不支持在同步过程中对正在同步的表和库进行这些操作。
