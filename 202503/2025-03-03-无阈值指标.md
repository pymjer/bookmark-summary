# 无阈值指标
- URL: https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_4_PerformanceMetrics/ThresholdFree.html
- Added At: 2025-03-03 02:21:09
- [Link To Text](2025-03-03-无阈值指标_raw.md)

## TL;DR
本文介绍了无阈值度量指标，包括ROC曲线和PR曲线，用于评估欺诈检测系统性能。ROC曲线通过比较TPR和FPR评估分类器性能，而PR曲线强调精确度和召回率。实验使用2018年数据，比较了不同模型，发现ROC和PR曲线提供了不同视角。操作性考虑中，FPR限制和不同度量标准下的性能排序也有所不同。

## Summary
# 无阈值度量指标
## 1. 接收者操作特征（ROC）曲线
- **定义**：通过绘制不同分类阈值下的真正例率（TPR）与假正例率（FPR）来获得。
- **标准**：在文献中，ROC曲线是评估欺诈检测系统性能的事实标准。
- **性能比较**：一个分类器K在ROC空间中被认为比分类器W表现更好，只有当K的曲线始终优于W。
- **最佳分类器**：对应于ROC空间中的点（0,1），即没有假阴性和假阳性。
- **随机分类器**：性能沿连接左下角到右上角的对角线分布。
- **AUC ROC**：通过梯形法则计算，提供TPR和FPR的预期概率。
- **Python实现**：使用`sklearn.metrics`库中的`roc_curve`函数计算阈值和对应的FPR和TPR。

## 2. 精确度-召回率（PR）曲线
- **定义**：通过绘制不同分类阈值下的精确度与召回率（TPR）来获得。
- **优势**：强调那些既能保持高召回率又能保持高精确度的分类器。
- **AUC解释**：PR曲线下的面积（AUC）没有统计学解释，但PR曲线与ROC曲线存在一一对应关系。
- **随机分类器性能**：取决于类别不平衡，对于欺诈检测问题，AP比AUC ROC更有意义，因为它更好地反映了类别不平衡的挑战。
- **绘制方法**：应使用`step`函数绘制PR曲线，并使用AP作为AUC的度量。

## 3. 实验设置与结果
- **数据**：使用2018年7月25日至8月14日的数据，其中包含58264笔交易，57879笔正常交易和385笔欺诈交易。
- **模型**：比较了逻辑回归、决策树（深度为2和无限深度）、随机森林和提升模型的性能。
- **ROC曲线分析**：决策树性能最低，而随机森林、逻辑回归和提升模型性能相似。
- **PR曲线分析**：PR曲线和ROC曲线给出了不同分类器性能的不同视角，PR曲线实际上是ROC曲线在很低的假正例率值下的放大版本。

## 4. 操作性考虑
- **FPR限制**：由于欺诈检测中需要手动检查的卡片数量非常有限，因此对于FPR值的实际关注主要集中在非常低的范围内。
- **性能排序**：根据不同的度量标准（ROC AUC vs. AP），分类器的性能排序可能会有所不同。
